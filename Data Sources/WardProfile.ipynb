{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:33:22.946032Z",
     "start_time": "2024-03-19T20:33:21.788421Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text,  Column, Integer, ForeignKey\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:29:45.536594Z",
     "start_time": "2024-03-19T20:29:45.510415Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# connection to PostgreSQL database\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql+psycopg2://postgres:2002\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m40Thaovy@localhost:5432/main\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# postgresql+psycopg2://<username>:<password>@<host>:<port>/<database>  with username being default 'postgres'\u001b[39;00m\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/util/deprecations.py:281\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    275\u001b[0m         _warn_with_version(\n\u001b[1;32m    276\u001b[0m             messages[m],\n\u001b[1;32m    277\u001b[0m             versions[m],\n\u001b[1;32m    278\u001b[0m             version_warnings[m],\n\u001b[1;32m    279\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    280\u001b[0m         )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/engine/create.py:599\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    598\u001b[0m             dbapi_args[k] \u001b[38;5;241m=\u001b[39m pop_kwarg(k)\n\u001b[0;32m--> 599\u001b[0m     dbapi \u001b[38;5;241m=\u001b[39m \u001b[43mdbapi_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdbapi_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m dialect_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dbapi\n\u001b[1;32m    603\u001b[0m dialect_args\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_linting\u001b[39m\u001b[38;5;124m\"\u001b[39m, compiler\u001b[38;5;241m.\u001b[39mNO_LINTING)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py:690\u001b[0m, in \u001b[0;36mPGDialect_psycopg2.import_dbapi\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_dbapi\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsycopg2\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psycopg2\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "# connection to PostgreSQL database\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:2002%40Thaovy@localhost:5432/main\")\n",
    "# postgresql+psycopg2://<username>:<password>@<host>:<port>/<database>  with username being default 'postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARD DIMENSION\n",
    "WardDimension = pd.read_csv(\n",
    "    \"WardNameNumbers.csv\", encoding=\"ISO-8859-1\", low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "WardDimension.rename(columns={\"Ward Number\": \"Ward_ID\"}, inplace=True)\n",
    "WardDimension.rename(columns={\"Ward Name\": \"Ward_Name\"}, inplace=True)\n",
    "\n",
    "# change data types\n",
    "WardDimension[\"Ward_ID\"] = \"Ward \" + WardDimension[\"Ward_ID\"].astype(str)\n",
    "WardDimension[\"Ward_Name\"] = WardDimension[\"Ward_Name\"].astype(str)\n",
    "\n",
    "# output final ward dimension\n",
    "# WardDimension.to_csv('WardDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "WardDimension.to_sql(\"WardDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "WardDimension['Ward_Key'] = range(1, len(WardDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Ward_Key'] + [col for col in WardDimension.columns if col != 'Ward_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "WardDimension = WardDimension[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDUCATION DIMENSION\n",
    "education_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(833),\n",
    "    nrows=16,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "education_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(978),\n",
    "    nrows=17,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# rename 'Education' column to 'Education_Level' before melting\n",
    "education_data2016.rename(columns={\"Education\": \"Education_Level\"}, inplace=True)\n",
    "education_data2021.rename(columns={\"Education\": \"Education_Level\"}, inplace=True)\n",
    "\n",
    "# Filter out rows where 'Education_Level' column is not NA (i.e., not empty)\n",
    "education_data2016 = education_data2016[education_data2016[\"Education_Level\"].notna()]\n",
    "education_data2021 = education_data2021[education_data2021[\"Education_Level\"].notna()]\n",
    "\n",
    "# remove all spaces in education_level column\n",
    "education_data2016[\"Education_Level\"] = education_data2016[\n",
    "    \"Education_Level\"\n",
    "].str.strip()\n",
    "education_data2021[\"Education_Level\"] = education_data2021[\n",
    "    \"Education_Level\"\n",
    "].str.strip()\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Education_Level', and 'Population' columns\n",
    "education_data2016 = pd.melt(\n",
    "    education_data2016,\n",
    "    id_vars=[\"Education_Level\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "education_data2016[\"Year\"] = 2016\n",
    "education_data2021 = pd.melt(\n",
    "    education_data2021,\n",
    "    id_vars=[\"Education_Level\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "education_data2021[\"Year\"] = 2021\n",
    "\n",
    "# merge the datasets\n",
    "EducationDimension = pd.concat(\n",
    "    [education_data2016, education_data2021], ignore_index=True\n",
    ")\n",
    "\n",
    "# change data types\n",
    "EducationDimension[\"Population\"] = EducationDimension[\"Population\"].astype(int)\n",
    "EducationDimension[\"Ward_ID\"] = EducationDimension[\"Ward_ID\"].astype(str)\n",
    "EducationDimension[\"Education_Level\"] = EducationDimension[\"Education_Level\"].astype(\n",
    "    str\n",
    ")\n",
    "\n",
    "# output final education dimension\n",
    "# EducationDimension.to_csv('EducationDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "EducationDimension.to_sql(\"EducationDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EducationDimension' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate surrogate key named 'Education_Key'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m EducationDimension[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation_Key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mEducationDimension\u001b[49m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Move 'Education_Key' to the first position\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation_Key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m EducationDimension\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation_Key\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EducationDimension' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "EducationDimension['Education_Key'] = range(1, len(EducationDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Education_Key'] + [col for col in EducationDimension.columns if col != 'Education_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "EducationDimension = EducationDimension[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EducationDimension' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mEducationDimension\u001b[49m[:\u001b[38;5;241m20\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EducationDimension' is not defined"
     ]
    }
   ],
   "source": [
    "print(EducationDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE DIMENSION\n",
    "age_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(0),\n",
    "    nrows=21,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "age_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(0),\n",
    "    nrows=21,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "age_data2016.rename(columns={\"Population\": \"Age_Range\"}, inplace=True)\n",
    "age_data2021.rename(columns={\"Population\": \"Age_Range\"}, inplace=True)\n",
    "\n",
    "# Filter out rows where 'Age' column is not NA (i.e., not empty)\n",
    "age_data2016 = age_data2016[age_data2016[\"Age_Range\"].notna()]\n",
    "age_data2021 = age_data2021[age_data2021[\"Age_Range\"].notna()]\n",
    "\n",
    "# remove spaces\n",
    "age_data2016[\"Age_Range\"] = age_data2016[\"Age_Range\"].str.strip()\n",
    "age_data2021[\"Age_Range\"] = age_data2021[\"Age_Range\"].str.strip()\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Age', and 'Population' columns\n",
    "age_data2016 = pd.melt(\n",
    "    age_data2016, id_vars=[\"Age_Range\"], var_name=\"Ward_ID\", value_name=\"Population\"\n",
    ")\n",
    "age_data2016[\"Year\"] = 2016\n",
    "age_data2021 = pd.melt(\n",
    "    age_data2021, id_vars=[\"Age_Range\"], var_name=\"Ward_ID\", value_name=\"Population\"\n",
    ")\n",
    "age_data2021[\"Year\"] = 2021\n",
    "\n",
    "# merge the datasets\n",
    "AgeDimension = pd.concat([age_data2016, age_data2021], ignore_index=True)\n",
    "\n",
    "# change data types\n",
    "AgeDimension[\"Population\"] = AgeDimension[\"Population\"].astype(int)\n",
    "AgeDimension[\"Ward_ID\"] = AgeDimension[\"Ward_ID\"].astype(str)\n",
    "AgeDimension[\"Age_Range\"] = AgeDimension[\"Age_Range\"].astype(str)\n",
    "\n",
    "# output final age dimension\n",
    "# AgeDimension.to_csv('AgeDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "AgeDimension.to_sql(\"AgeDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "AgeDimension['Age_Key'] = range(1, len(AgeDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Age_Key'] + [col for col in AgeDimension.columns if col != 'Age_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "AgeDimension = AgeDimension[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AgeDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMPLOYMENT DIMENSION\n",
    "employment_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(1163),\n",
    "    nrows=12,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "employment_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(1297),\n",
    "    nrows=12,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Filter out rows where 'Employment' column is not NA (i.e., not empty)\n",
    "employment_data2016 = employment_data2016[employment_data2016[\"Employment\"].notna()]\n",
    "employment_data2021 = employment_data2021[employment_data2021[\"Employment\"].notna()]\n",
    "\n",
    "# Removing the numbers and spaces before each employment type\n",
    "employment_data2016[\"Employment\"] = employment_data2016[\"Employment\"].str.strip()\n",
    "employment_data2021[\"Employment\"] = employment_data2021[\"Employment\"].str.strip()\n",
    "employment_data2016[\"Employment\"] = employment_data2016[\"Employment\"].str.replace(\n",
    "    r\"^\\s*\\d+\\s+\", \"\", regex=True\n",
    ")\n",
    "employment_data2021[\"Employment\"] = employment_data2021[\"Employment\"].str.replace(\n",
    "    r\"^\\s*\\d+\\s+\", \"\", regex=True\n",
    ")\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Employment', and 'Population' columns\n",
    "employment_data2016 = pd.melt(\n",
    "    employment_data2016,\n",
    "    id_vars=[\"Employment\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "employment_data2016[\"Year\"] = 2016\n",
    "employment_data2021 = pd.melt(\n",
    "    employment_data2021,\n",
    "    id_vars=[\"Employment\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "employment_data2021[\"Year\"] = 2021\n",
    "\n",
    "# merge the datasets\n",
    "EmploymentDimension = pd.concat(\n",
    "    [employment_data2016, employment_data2021], ignore_index=True\n",
    ")\n",
    "\n",
    "# change data types\n",
    "EmploymentDimension[\"Population\"] = EmploymentDimension[\"Population\"].astype(int)\n",
    "EmploymentDimension[\"Ward_ID\"] = EmploymentDimension[\"Ward_ID\"].astype(str)\n",
    "EmploymentDimension[\"Employment\"] = EmploymentDimension[\"Employment\"].astype(str)\n",
    "\n",
    "\n",
    "# output final education dimension\n",
    "# EmploymentDimension.to_csv('EmploymentDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "EmploymentDimension.to_sql(\n",
    "    \"EmploymentDimension\", engine, if_exists=\"append\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "EmploymentDimension['Employment_Key'] = range(1, len(EmploymentDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Employment_Key'] + [col for col in EmploymentDimension.columns if col != 'Employment_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "EmploymentDimension = EmploymentDimension[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EmploymentDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDUSTRY DIMENSION\n",
    "industry_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(1176),\n",
    "    nrows=22,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "industry_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(1310),\n",
    "    nrows=22,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Filter out rows where 'Industry' column is not NA (i.e., not empty)\n",
    "industry_data2016 = industry_data2016[industry_data2016[\"Industry\"].notna()]\n",
    "industry_data2021 = industry_data2021[industry_data2021[\"Industry\"].notna()]\n",
    "\n",
    "# Removing the numbers and spaces before each industry type\n",
    "industry_data2016[\"Industry\"] = industry_data2016[\"Industry\"].str.strip()\n",
    "industry_data2021[\"Industry\"] = industry_data2021[\"Industry\"].str.strip()\n",
    "industry_data2016[\"Industry\"] = industry_data2016[\"Industry\"].str.replace(\n",
    "    r\"^\\s*\\d+(-\\d+)?\\s+\", \"\", regex=True\n",
    ")\n",
    "industry_data2021[\"Industry\"] = industry_data2021[\"Industry\"].str.replace(\n",
    "    r\"^\\s*\\d+(-\\d+)?\\s+\", \"\", regex=True\n",
    ")\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Industry', and 'Population' columns\n",
    "industry_data2016 = pd.melt(\n",
    "    industry_data2016, id_vars=[\"Industry\"], var_name=\"Ward_ID\", value_name=\"Population\"\n",
    ")\n",
    "industry_data2016[\"Year\"] = 2016\n",
    "industry_data2021 = pd.melt(\n",
    "    industry_data2021, id_vars=[\"Industry\"], var_name=\"Ward_ID\", value_name=\"Population\"\n",
    ")\n",
    "industry_data2021[\"Year\"] = 2021\n",
    "\n",
    "# merge the datasets\n",
    "IndustryDimension = pd.concat([industry_data2016, industry_data2021], ignore_index=True)\n",
    "\n",
    "# change data types\n",
    "IndustryDimension[\"Population\"] = IndustryDimension[\"Population\"].astype(int)\n",
    "IndustryDimension[\"Ward_ID\"] = IndustryDimension[\"Ward_ID\"].astype(str)\n",
    "IndustryDimension[\"Industry\"] = IndustryDimension[\"Industry\"].astype(str)\n",
    "\n",
    "# output final education dimension\n",
    "# IndustryDimension.to_csv('IndustryDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "IndustryDimension.to_sql(\"IndustryDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "IndustryDimension['Industry_Key'] = range(1, len(IndustryDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Industry_Key'] + [col for col in IndustryDimension.columns if col != 'Industry_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "IndustryDimension = IndustryDimension[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IndustryDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOME DIMENSION\n",
    "income_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(1252),\n",
    "    nrows=17,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "income_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(1389),\n",
    "    nrows=17,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Filter out rows where 'Income' column is not NA (i.e., not empty)\n",
    "income_data2016 = income_data2016[income_data2016[\"Income\"].notna()]\n",
    "income_data2021 = income_data2021[income_data2021[\"Income\"].notna()]\n",
    "\n",
    "# change value of one of income ranges\n",
    "income_data2016.loc[\n",
    "    income_data2016[\"Income\"].str.contains(\"Total - Total income groups\"), \"Income\"\n",
    "] = \"Total Income Groups\"\n",
    "income_data2021.loc[\n",
    "    income_data2021[\"Income\"].str.contains(\"Total - Total Income groups\"), \"Income\"\n",
    "] = \"Total Income Groups\"\n",
    "\n",
    "# Removing the spaces before each income\n",
    "income_data2016[\"Income\"] = income_data2016[\"Income\"].str.strip()\n",
    "income_data2021[\"Income\"] = income_data2021[\"Income\"].str.strip()\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Income', and 'Population' columns\n",
    "income_data2016[\"Year\"] = 2016\n",
    "income_data2021[\"Year\"] = 2021\n",
    "income_data2016 = pd.melt(\n",
    "    income_data2016,\n",
    "    id_vars=[\"Income\", \"Year\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "income_data2021 = pd.melt(\n",
    "    income_data2021,\n",
    "    id_vars=[\"Income\", \"Year\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "columns_order = [col for col in income_data2016.columns if col != \"Year\"] + [\"Year\"]\n",
    "income_data2016 = income_data2016[columns_order]\n",
    "income_data2021 = income_data2021[columns_order]\n",
    "\n",
    "# merge the datasets\n",
    "IncomeDimension = pd.concat([income_data2016, income_data2021], ignore_index=True)\n",
    "\n",
    "# change data types\n",
    "IncomeDimension[\"Population\"] = IncomeDimension[\"Population\"].astype(int)\n",
    "IncomeDimension[\"Ward_ID\"] = IncomeDimension[\"Ward_ID\"].astype(str)\n",
    "IncomeDimension[\"Income\"] = IncomeDimension[\"Income\"].astype(str)\n",
    "\n",
    "# output final income dimension\n",
    "# IncomeDimension.to_csv('IncomeDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "IncomeDimension.to_sql(\"IncomeDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "IncomeDimension['Income_Key'] = range(1, len(IncomeDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Income_Key'] + [col for col in IncomeDimension.columns if col != 'Income_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "IncomeDimension = IncomeDimension[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IncomeDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETHNOCULTURAL DIMENSION\n",
    "ethnicity_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(851),\n",
    "    nrows=280,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "ethnicity_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(1013),\n",
    "    nrows=252,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Filter out rows where 'Ethnocultural' column is not NA (i.e., not empty)\n",
    "ethnicity_data2016 = ethnicity_data2016[ethnicity_data2016[\"Ethnoculture\"].notna()]\n",
    "ethnicity_data2021 = ethnicity_data2021[ethnicity_data2021[\"Ethnoculture\"].notna()]\n",
    "\n",
    "# change value of one of income ranges\n",
    "ethnicity_data2016.loc[\n",
    "    ethnicity_data2016[\"Ethnoculture\"].str.contains(\"Total - Ethnic origin\"),\n",
    "    \"Ethnoculture\",\n",
    "] = \"Total Ethnic Origin\"\n",
    "ethnicity_data2021.loc[\n",
    "    ethnicity_data2021[\"Ethnoculture\"].str.contains(\"Total - Ethnic origin\"),\n",
    "    \"Ethnoculture\",\n",
    "] = \"Total Ethnic Origin\"\n",
    "\n",
    "# Removing the spaces before each ethnicity\n",
    "ethnicity_data2016[\"Ethnoculture\"] = ethnicity_data2016[\"Ethnoculture\"].str.strip()\n",
    "ethnicity_data2021[\"Ethnoculture\"] = ethnicity_data2021[\"Ethnoculture\"].str.strip()\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Ethnocultural', and 'Population' columns\n",
    "ethnicity_data2016[\"Year\"] = 2016\n",
    "ethnicity_data2021[\"Year\"] = 2021\n",
    "ethnicity_data2016 = pd.melt(\n",
    "    ethnicity_data2016,\n",
    "    id_vars=[\"Ethnoculture\", \"Year\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "ethnicity_data2021 = pd.melt(\n",
    "    ethnicity_data2021,\n",
    "    id_vars=[\"Ethnoculture\", \"Year\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "columns_order = [col for col in ethnicity_data2016.columns if col != \"Year\"] + [\"Year\"]\n",
    "ethnicity_data2016 = ethnicity_data2016[columns_order]\n",
    "ethnicity_data2021 = ethnicity_data2021[columns_order]\n",
    "\n",
    "# merge the datasets\n",
    "EthnoculturalDimension = pd.concat(\n",
    "    [ethnicity_data2016, ethnicity_data2021], ignore_index=True\n",
    ")\n",
    "\n",
    "# change data types\n",
    "EthnoculturalDimension[\"Population\"] = EthnoculturalDimension[\"Population\"].astype(int)\n",
    "EthnoculturalDimension[\"Ward_ID\"] = EthnoculturalDimension[\"Ward_ID\"].astype(str)\n",
    "EthnoculturalDimension[\"Ethnoculture\"] = EthnoculturalDimension[\"Ethnoculture\"].astype(\n",
    "    str\n",
    ")\n",
    "\n",
    "# output final ethnicity dimension\n",
    "# EthnoculturalDimension.to_csv('EthnoculturalDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "EthnoculturalDimension.to_sql(\n",
    "    \"EthnoculturalDimension\", engine, if_exists=\"append\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "EthnoculturalDimension['Ethnocultural_Key'] = range(1, len(EthnoculturalDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Ethnocultural_Key'] + [col for col in EthnoculturalDimension.columns if col != 'Ethnocultural_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "EthnoculturalDimension = EthnoculturalDimension[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EthnoculturalDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOUSEHOLD DIMENSION\n",
    "household_data2016 = pd.read_csv(\n",
    "    \"WardProfile2016.csv\",\n",
    "    skiprows=range(98),\n",
    "    nrows=9,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "household_data2021 = pd.read_csv(\n",
    "    \"WardProfile2021.csv\",\n",
    "    skiprows=range(108),\n",
    "    nrows=9,\n",
    "    header=0,\n",
    "    encoding=\"ISO-8859-1\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "# Filter out rows where 'Household' column is not NA (i.e., not empty)\n",
    "household_data2016 = household_data2016[household_data2016[\"Household\"].notna()]\n",
    "household_data2021 = household_data2021[household_data2021[\"Household\"].notna()]\n",
    "\n",
    "# change value of one of income ranges\n",
    "household_data2016.loc[\n",
    "    household_data2016[\"Household\"].str.contains(\n",
    "        \"Total - Private households by household\"\n",
    "    ),\n",
    "    \"Household\",\n",
    "] = \"Total Household\"\n",
    "household_data2021.loc[\n",
    "    household_data2021[\"Household\"].str.contains(\n",
    "        \"Total - Private households by household\"\n",
    "    ),\n",
    "    \"Household\",\n",
    "] = \"Total Household\"\n",
    "\n",
    "\n",
    "# Removing the spaces before each household type\n",
    "household_data2016[\"Household\"] = household_data2016[\"Household\"].str.strip()\n",
    "household_data2021[\"Household\"] = household_data2021[\"Household\"].str.strip()\n",
    "\n",
    "# Melt the DataFrame to get 'Ward_ID', 'Household', and 'Population' columns\n",
    "household_data2016[\"Year\"] = 2016\n",
    "household_data2021[\"Year\"] = 2021\n",
    "household_data2016 = pd.melt(\n",
    "    household_data2016,\n",
    "    id_vars=[\"Household\", \"Year\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "household_data2021 = pd.melt(\n",
    "    household_data2021,\n",
    "    id_vars=[\"Household\", \"Year\"],\n",
    "    var_name=\"Ward_ID\",\n",
    "    value_name=\"Population\",\n",
    ")\n",
    "columns_order = [col for col in household_data2016.columns if col != \"Year\"] + [\"Year\"]\n",
    "household_data2016 = household_data2016[columns_order]\n",
    "household_data2021 = household_data2021[columns_order]\n",
    "\n",
    "# Merge the datasets\n",
    "HouseholdDimension = pd.concat(\n",
    "    [household_data2016, household_data2021], ignore_index=True\n",
    ")\n",
    "\n",
    "\n",
    "# change data types\n",
    "HouseholdDimension[\"Ward_ID\"] = HouseholdDimension[\"Ward_ID\"].astype(str)\n",
    "HouseholdDimension[\"Household\"] = HouseholdDimension[\"Household\"].astype(str)\n",
    "\n",
    "# rename column\n",
    "HouseholdDimension.rename(columns={\"Household\": \"Household_Description\"}, inplace=True)\n",
    "\n",
    "# output final ethnicity dimension\n",
    "# HouseholdDimension.to_csv('HouseholdDimension.csv', encoding='ISO-8859-1', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "HouseholdDimension.to_sql(\"HouseholdDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate surrogate key named 'Education_Key'\n",
    "HouseholdDimension['Household_Key'] = range(1, len(HouseholdDimension) + 1)\n",
    "\n",
    "# Move 'Education_Key' to the first position\n",
    "cols = ['Household_Key'] + [col for col in HouseholdDimension.columns if col != 'Household_Key']\n",
    "\n",
    "# Reorder the DataFrame to have 'Education_Key' as the first column\n",
    "HouseholdDimension = HouseholdDimension[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(HouseholdDimension[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHELTER DIMENSION\n",
    "# 2021\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"WardProfile2021.csv\", encoding=\"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "# Define the indices\n",
    "tenant_costs_index = 1373\n",
    "owner_costs_index = 1377\n",
    "\n",
    "tenant_percent_spending = 1374\n",
    "owner_percent_spending = 1378\n",
    "\n",
    "tenant_households = 1372\n",
    "owner_households = 1376\n",
    "\n",
    "# Create the Ward_IDs list based on the column headers\n",
    "ward_ids = df.columns[1:]\n",
    "\n",
    "tenant_data = []\n",
    "owner_data = []\n",
    "\n",
    "\n",
    "for i, ward_id in enumerate(ward_ids):\n",
    "    tenant_data.append(\n",
    "        {\n",
    "            \"Household_Type\": \"Tenant\",\n",
    "            \"Ward_ID\": ward_id,\n",
    "            \"Total_Households\": df.iloc[tenant_households, i + 1],\n",
    "            \"Average_Monthly_Shelter_Costs\": df.iloc[tenant_costs_index, i + 1],\n",
    "            \"Percent_Spending_30_Percent_Or_More_On_Shelter\": df.iloc[\n",
    "                tenant_percent_spending, i + 1\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    owner_data.append(\n",
    "        {\n",
    "            \"Household_Type\": \"Owner\",\n",
    "            \"Ward_ID\": ward_id,\n",
    "            \"Total_Households\": df.iloc[owner_households, i + 1],\n",
    "            \"Average_Monthly_Shelter_Costs\": df.iloc[owner_costs_index, i + 1],\n",
    "            \"Percent_Spending_30_Percent_Or_More_On_Shelter\": df.iloc[\n",
    "                owner_percent_spending, i + 1\n",
    "            ],\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the tenant and owner data\n",
    "combined_data = tenant_data + owner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016\n",
    "# Load the CSV file\n",
    "df1 = pd.read_csv(\"WardProfile2016.csv\", encoding=\"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "# Define the indices\n",
    "tenant_costs_index = 1239\n",
    "owner_costs_index = 1243\n",
    "\n",
    "tenant_percent_spending = 1240\n",
    "owner_percent_spending = 1244\n",
    "\n",
    "tenant_households = 1238\n",
    "owner_households = 1242\n",
    "\n",
    "# Create the Ward_IDs list based on the column headers\n",
    "ward_ids = df1.columns[1:]\n",
    "\n",
    "tenant_data = []\n",
    "owner_data = []\n",
    "\n",
    "for i, ward_id in enumerate(ward_ids):\n",
    "    tenant_data.append(\n",
    "        {\n",
    "            \"Household_Type\": \"Tenant\",\n",
    "            \"Ward_ID\": ward_id,\n",
    "            \"Total_Households\": df1.iloc[tenant_households, i + 1],\n",
    "            \"Average_Monthly_Shelter_Costs\": df1.iloc[tenant_costs_index, i + 1],\n",
    "            \"Percent_Spending_30_Percent_Or_More_On_Shelter\": df1.iloc[\n",
    "                tenant_percent_spending, i + 1\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    owner_data.append(\n",
    "        {\n",
    "            \"Household_Type\": \"Owner\",\n",
    "            \"Ward_ID\": ward_id,\n",
    "            \"Total_Households\": df1.iloc[owner_households, i + 1],\n",
    "            \"Average_Monthly_Shelter_Costs\": df1.iloc[owner_costs_index, i + 1],\n",
    "            \"Percent_Spending_30_Percent_Or_More_On_Shelter\": df1.iloc[\n",
    "                owner_percent_spending, i + 1\n",
    "            ],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the tenant and owner data\n",
    "combined_data2 = tenant_data + owner_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_data2[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ShelterDimension2016 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mcombined_data2\u001b[49m)\n\u001b[1;32m      3\u001b[0m ShelterDimension2021 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(combined_data)\n\u001b[1;32m      5\u001b[0m ShelterDimension2016[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2016\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_data2' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame\n",
    "ShelterDimension2016 = pd.DataFrame(combined_data2)\n",
    "ShelterDimension2021 = pd.DataFrame(combined_data)\n",
    "\n",
    "ShelterDimension2016[\"Year\"] = 2016\n",
    "ShelterDimension2021[\"Year\"] = 2021\n",
    "\n",
    "# merge the datasets\n",
    "ShelterDimension = pd.concat(\n",
    "    [ShelterDimension2016, ShelterDimension2021], ignore_index=True\n",
    ")\n",
    "\n",
    "# clean data and change data types\n",
    "ShelterDimension[\"Average_Monthly_Shelter_Costs\"] = (\n",
    "    ShelterDimension[\"Average_Monthly_Shelter_Costs\"]\n",
    "    .str.replace(\"$\", \"\")\n",
    "    .str.replace(\",\", \"\")\n",
    "    .astype(int)\n",
    ")\n",
    "ShelterDimension[\"Percent_Spending_30_Percent_Or_More_On_Shelter\"] = (\n",
    "    ShelterDimension[\"Percent_Spending_30_Percent_Or_More_On_Shelter\"]\n",
    "    .str.replace(\"%\", \"\")\n",
    "    .astype(float)\n",
    ")\n",
    "ShelterDimension[\"Total_Households\"] = ShelterDimension[\"Total_Households\"].astype(int)\n",
    "ShelterDimension[\"Household_Type\"] = ShelterDimension[\"Household_Type\"].astype(str)\n",
    "ShelterDimension[\"Ward_ID\"] = ShelterDimension[\"Ward_ID\"].astype(str)\n",
    "\n",
    "# confirm the output\n",
    "# ShelterDimension.to_csv('ShelterDimension.csv', index=False)\n",
    "\n",
    "# load dataframe to database\n",
    "ShelterDimension.to_sql(\"ShelterDimension\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ShelterDimension[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
